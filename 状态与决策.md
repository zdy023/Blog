# 状态与决策<br>——对“强化学习”“马尔可夫决策”“动态规划”“状态空间理论”的一点理解

1. **马尔可夫决策**同**动态规划**的区别在于，**马尔可夫决策**中状态的转移是不确定的，而**动态规划**中考虑的状态的转移是确定的。
2. 自控2中学习的**状态空间理论**考虑的状态空间是线性的，而更多问题中的状态空间未必是是线性的；**最优控制理论**中的评价指标就相当于是累积值函数。
3. **强化学习**对于**马尔可夫决策**的最重要补充在于采样，即评价函数是通过采样来估计的，更准确地来说，所估计的是（累积）动作-值函数。
4. 从优化问题的角度来看，累积值函数就是优化问题的目标函数。
5. 这些理论的核心要素：
   * 状态、动作（决策、输入或称控制）与策略
   * 状态转移函数（确定性&非确定性）
   * 评价函数（回报函数、输出方程、观测值、单步/阶段指标）
   * 累积值函数（过程指标、目标函数）、Bellman最优化方程
   * （累积）动作-值函数
